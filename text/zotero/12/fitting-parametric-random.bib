@article{gebregziabher_fitting_2012,
	title = {Fitting parametric random effects models in very large data sets with application to {VHA} national data},
	volume = {12},
	rights = {http://creativecommons.org/licenses/by/2.0/},
	issn = {1471-2288},
	url = {http://www.biomedcentral.com/1471-2288/12/163/abstract},
	doi = {10.1186/1471-2288-12-163},
	abstract = {With the current focus on personalized medicine, patient/subject level inference is often of key interest in translational research. As a result, random effects models ({REM}) are becoming popular for patient level inference. However, for very large data sets that are characterized by large sample size, it can be difficult to fit {REM} using commonly available statistical software such as {SAS} since they require inordinate amounts of computer time and memory allocations beyond what are available preventing model convergence. For example, in a retrospective cohort study of over 800,000 Veterans with type 2 diabetes with longitudinal data over 5 years, fitting {REM} via generalized linear mixed modeling using currently available standard procedures in {SAS} (e.g. {PROC} {GLIMMIX}) was very difficult and same problems exist in Stata's gllamm or R's lme packages. Thus, this study proposes and assesses the performance of a meta regression approach and makes comparison with methods based on sampling of the full data.},
	pages = {163},
	number = {1},
	journaltitle = {{BMC} Medical Research Methodology},
	author = {Gebregziabher, Mulugeta and Egede, Leonard E. and Gilbert, Gregory E. and Hunt, Kelly J. and Nietert, Paul J. and Mauldin, Patrick},
	urldate = {2012-11-09},
	date = {2012-10-24},
	langid = {english}
}

