@online{kelly_overview_nodate,
	title = {Overview of Computer-Intensive Statistics},
	url = {http://www.hsrd.houston.med.va.gov/AdamKelly/resampling.html},
	abstract = {Excerpt: "Resampling procedures, also commonly referred to as computer intensive statistical inference procedures, may be used to assess the significance of a statistic in a hypothesis test or to determine the lower and upper bounds for a confidence interval when the usual assumptions of parametric statistical procedures are not met (Manly, 1991). Computer intensive procedures require the recomputation of hundreds or thousands of artificially constructed data sets. Like other nonparametric statistical procedures, these procedures existed as theory on paper long before they were brought into the practical mainstream. The Monte Carlo method of resampling, for example, was introduced by Barnard in 1963 (Noreen, 1989), but at that time could only be illustrated and implemented operationally on very small sample sizes.

However, with the advent of fast, inexpensive computing, essentially since around 1990, the use of computer intensive procedures has grown dramatically, particularly in the area of basic academic research. Actually, with the widespread availability of powerful personal computers and statistical software that even brings resampling-type methods right into the home, the name computer intensive seems today to be as anachronistic as it was descriptive just a few years ago."},
	author = {Kelly, P. Adam},
	urldate = {2009-03-04},
	tags = {Resampling methods, a02}
}

