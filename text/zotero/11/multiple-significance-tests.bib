@online{bland_multiple_nodate,
	title = {Multiple significance tests and the Bonferroni correction},
	url = {http://www-users.york.ac.uk/~mb55/intro/bonf.htm},
	abstract = {Excerpt: "If we test a null hypothesis which is in fact true, using 0.05 as the critical significance level, we have a probability of 0.95 of coming to a `not significant' (i.e. correct) conclusion. If we test two independent true null hypotheses, the probability that neither test will be significant is 0.95 times 0.95 = 0.90 (Section 6.2). If we test twenty such hypotheses the probability that none will be significant is 0.9520 = 0.36. This gives a probability of 1 - 0.36 = 0.64 of getting at least one significant result; we are more likely to get one than not. The expected number of spurious significant results is 20 times 0.05 = 1. Many medical research studies are published with large numbers of significance tests. These are not usually independent, being carried out on the same set of subjects, so the above calculations do not apply exactly. However, it is clear that if we go on testing long enough we will find something which is `significant'. We must beware of attaching too much importance to a lone significant result among a mass of non-significant ones. It may be the one in twenty which we should get by chance alone. "},
	author = {Bland, Martin},
	urldate = {2011-02-23}
}

