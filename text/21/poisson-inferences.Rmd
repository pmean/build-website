---
title: "Working with the Poisson distribution"
author: "Steve Simon"
source: "New"
date: "2020-08-30"
categories:
- Blog post
tags:
- Probability distributions
output: html_document
---

Many statistics, such as mortality statistics, are based on fundamental counting processes. If you want to understand these processes, you should start by trying to understand the Poisson distribution. Here's a brief introduction.

```{r setup}
suppressMessages(suppressWarnings(library(dplyr)))
suppressMessages(suppressWarnings(library(ggplot2)))
suppressMessages(suppressWarnings(library(magrittr)))
```

<!---More--->

### Definition of a Poisson distribution

A random variable X, defined on the set of non-negative integers (0, 1, 2, ...), is said to have a Poisson distribution (X ~ Pois($\lambda$) if 

$P[X=k]=\frac{\lambda^ke^{-k}}{k!}$ where $\lambda > 0$

### Mean and variance of a Poisson random variable.

Without too much difficulty, you can show that

$E[X]=\lambda$

$V[X]=\lambda$

### sums of Poisson random variables

If 

$X_1$ ~ Pois($\lambda_1$) and 

$X_2$ ~ Pois($\lambda_2$) and 

$X_1$ and $X_2$ are independent, then

$X_1+X_2$ ~ Pois($\lambda_1+\lambda_2$).

If you have series of Poisson random variables,

$X_1, X_2,...,X_n$ all indpendent and all with the same Pois($\lambda$) distribution, then

$\Sigma_{i=1}^n X_i$ ~ Pois($k \lambda$)

These properties and more are described on the [Wikipedia page on the Poisson distribution][pois1].

### Visualization of Poisson probabilities

```{r bar-charts}
data.frame(x=0:25) %>%
  mutate(p=dpois(x, 0.5)) %>%
  ggplot(aes(x,p)) +
    geom_col() +
    expand_limits(y=1) +
    ggtitle("Poisson probabilities with lambda=0.5")
data.frame(x=0:25) %>%
  mutate(p=dpois(x, 2)) %>%
  ggplot(aes(x,p)) +
    geom_col() +
    expand_limits(y=1) +
    ggtitle("Poisson probabilities with lambda=2")
data.frame(x=0:25) %>%
  mutate(p=dpois(x, 8)) %>%
  ggplot(aes(x,p)) +
    geom_col() +
    expand_limits(y=1) +
    ggtitle("Poisson probabilities with lambda=8")
```

### Relationship to the Binomial distribution

If Y has a binomial distribution with n trials and probability of success p (X ~ Bin(n,p)), then for large n and small p, you can approximate Y with X ~ Pois($\lambda$=np). Wikipedia has a [nice explanation][pois2] of this.

### Inference for unknown value of lambda

If you collect data on a single Poisson random variable X where the parameter $\lambda$ is unknown, then you can estimate $lambda$ with a reasonable amout of precision with just that one value.

$\hat{\lambda}=X$

and a crude $1-\alpha$ confidence interval for $\lambda$ is 

$X \pm z_{\alpha/2} \sqrt{X}$

This confidence interval does poorly for small values of $\lambda$ because of the skewness of the Poisson distribution. it also can sometimes produce confidence intervals with a negative lower limit.

### Estimation of a rate

A count X divided by a measure of time, T, is called a rate (R=X/T). If you assume that 

x ~ Pois($\lambda T$)

where T is known, but $\lambda$ is unknown, then a $1-\alpha$ confidence interval for $\lambda$ is 

$\frac{X}{T} \pm z_{\alpha/2} \frac{\sqrt{X}}{T}$

I have a [page on my website][simo1] that describes these calculations.

### An improved confidence interval

The natural log transformation helps produce a better confidence interval.

The general rule is that a nonlinear transformation leads to a similar change in the expected value, but a change in the variance that is related to the Taylor series expansion.

If X has an expected value, $\mu$ and a variance, $\sigma^2_x$, then g(X) can be written as

$g(X) \approx g(\mu)+(X-\mu)g'(\mu)$

which can be used to show that 

$Var(g(X))=(g'(\mu))^2 \sigma^2_x$

If 

X ~ Pois($\lambda T$) and

$Y = g(X) = ln(X)$, then

$g'(X)=\frac{1}{X}$, and

V[Y] $\approx (g'(\mu))^2 \sigma^2_x = (\frac{1}{\lambda T})^2 \lambda T = \frac{1}{\lambda T}$

An approximate $1-\alpha$ confidence interval for ln($\lambda  T$) is

$ln(X) \pm z_{\alpha/2} \sqrt{\frac{1}{X}}$

Exponentiate both sides to get a confidence interval for $\lambda T$.

Divide by T to get a confidence interval for $\lambda$.

The mathematical approach used here is known as the delta method and is [documented in general terms] on Wikipedia.

### Examples

The Pennsylvania Department of Health has a [web page][penn1] oulining calculations for rates with three simple examples. The infant mortality rate in Butler County in 1984 was 17 deaths out of 1,989 births. This is actually a proportion, but let's treat it as a rate here.

```{r}
x <- 17
n <- 1989
rate <- x/n
rate
```

This rate is difficult to read because all of the leading zeros. So it is common practice to quote it not as a rate per live births, but a rate per 1,000 live births.

```{r}
rate_per_thousand <- rate*1000
rate_per_thousand
```

To construct a confidence interval for the rate, first start with a confidence interval for the count rather than the rate.

```{r}
lo <- 
hi <- x+1.96*sqrt(x)
count_ci <- c(x-1.96*sqrt(x), x+1.96*sqrt(x))
count_ci
```

Then convert from a count to a rate.

```{r}
rate_ci <- count_ci * 1000 / n
rate_ci
```

It's always a good idea to round your results.

```{r}
round(rate_ci, 1)
```

Now let's try it using the improved formula. First build a confidence interval for the log count.

```{r}
log_count <- log(x)
log_ci <- c(log_count-1.96*sqrt(1/x), log_count+1.96*sqrt(1/x))
log_ci
```

Back transform to the original scale.

```{r}
back_transformed_ci <- exp(log_ci)
back_transformed_ci
```

Convert from a count to a rate

```{r}
rate_ci <- back_transformed_ci * 1000 / n
rate_ci
```

And again remember to round your final result.

```{r}
round(rate_ci, 1)
```

Notice that the rate (`r round(rate_per_thousand, 2)`) is not in the middle of the interval. It is slightly closer to the lower limit than the upper limit. This reflects the skewness in the Poisson distribution and provides a slightly more accurate interval.

### On your own

The reference also includes an infant mortality rate for the city of Philadelphia. There were 388 infant deaths out of 24,979 live births. Show that the 95% confidence interval for the infant mortality rate in Philadelphia is 14.0 to 17.1.
            

Notice, by the way, how much narrower the confidence interval is when it is based on 388 deaths rather than 17.
            
### References

[simo1]: http://www.pmean.com/07/ConfidenceIntervalForRate.html

[penn1]: https://www.health.pa.gov/topics/HealthStatistics/Statistical-Resources/UnderstandingHealthStats/Documents/Confidence_Intervals_for_a_Crude_Rate.pdf

[delt1]: https://en.wikipedia.org/wiki/Delta_method

[delt2]: https://en.wikipedia.org/wiki/Taylor_expansions_for_the_moments_of_functions_of_random_variables

[pois1]: https://en.wikipedia.org/wiki/Poisson_distribution

[pois2]: https://en.wikipedia.org/wiki/Binomial_distribution#Poisson_approximation

http://www.pmean.com/definitions/or.htm

http://www.pmean.com/01/oddsratio.html

http://www.pmean.com/04/Rates.html

https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005510

