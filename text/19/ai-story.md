---
title: "How a Feel-Good AI Story Went Wrong in Flint"
author: "Steve Simon"
source: "http://blog.pmean.com/ai-story/"
date: "2019-01-09"
categories:
- Recommendation
tags:
- Data science
- Ethics in research
- Human side of statistics
output: html_document
page_update: complete
---

## A machine learning model in Flint, MI

[![](http://www.pmean.com/images/19/ai-story01.png)][mad1]

<div class="notes">

Building a great statistical model does no one any good if it doesn't pay attention to non-statistical issues. This story talks about a machine learning model to identify which houses in Flint Michagan that were the best candidates for removal of lead pipes. The model worked fairly well, but came up against problems like individual city council members wanting to assure their constituents that enough was being done in their district. I'm not sure what the actual moral of this story is, but it does serve as a warning to be careful when you are modeling data in a contentous area.

Alexis C. Madrigal. How a Feel-Good AI Story Went Wrong in Flint. The Atlantic, 2019-01-03. Available in [html
format][mad1]. About 3,500 words.

[mad1]: https://www.theatlantic.com/technology/archive/2019/01/how-machine-learning-found-flints-lead-pipes/578692/

</div>
